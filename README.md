# Aprendizaje Autom√°tico Nivel 2 üöÄ

## √çndice

1. [Resumen](#1-resumen)
2. [Objetivos de aprendizaje](#2-objetivos-de-aprendizaje)
3. [Descripci√≥n general del aprendizaje autom√°tico cl√°sico](#3-descripci√≥n-general-del-aprendizaje-autom√°tico-cl√°sico)
    - [Aprendizaje supervisado](#aprendizaje-supervisado)
    - [Aprendizaje no supervisado](#aprendizaje-no-supervisado)
4. [Entrenamiento de un modelo simple de aprendizaje autom√°tico](#4-entrenamiento-de-un-modelo-simple-de-aprendizaje-autom√°tico)
5. [M√©tricas de rendimiento](#5-m√©tricas-de-rendimiento)
6. [Validaci√≥n cruzada](#6-validaci√≥n-cruzada)
7. [Evaluaci√≥n del Modelo y Ajuste de Hiperpar√°metros](#7-evaluaci√≥n-del-modelo-y-ajuste-de-hiperpar√°metros)
    - [Evaluaci√≥n del modelo](#evaluaci√≥n-del-modelo)
    - [Ajuste de hiperpar√°metros](#ajuste-de-hiperpar√°metros)
8. [Conclusi√≥n y Pr√≥ximos pasos](#8-conclusi√≥n-y-pr√≥ximos-pasos)

## 1. Resumen

En el Nivel 1, sentamos las bases del aprendizaje autom√°tico centr√°ndonos en las etapas iniciales de cualquier proyecto de ML: comprender qu√© es el aprendizaje autom√°tico y c√≥mo preparar los datos para el modelado.

La semana pasada, exploramos:

- ‚úÖ ¬øQu√© es el aprendizaje autom√°tico?
- ‚úÖ C√≥mo depurar y transformar datos sin procesar en un formato utilizable
  - Trabajo con archivos CSV, gesti√≥n de valores faltantes, eliminaci√≥n de valores at√≠picos y visualizaci√≥n b√°sica de datos
  - Escalado de caracter√≠sticas num√©ricas y codificaci√≥n de variables categ√≥ricas
- ‚úÖ La importancia de la √©tica, la equidad y los valores humanos en la construcci√≥n de sistemas de IA responsables

Esta semana, iremos m√°s all√° de la preparaci√≥n de datos y hablaremos sobre las etapas restantes del proceso de aprendizaje autom√°tico.

- C√≥mo elegir y entrenar un modelo
- C√≥mo evaluar el rendimiento del modelo utilizando las m√©tricas adecuadas
- C√≥mo usar la validaci√≥n cruzada para garantizar resultados fiables
- C√≥mo perfeccionar tu modelo mediante la optimizaci√≥n de hiperpar√°metros
- Y, por √∫ltimo, c√≥mo preparar tu modelo para su presentaci√≥n o implementaci√≥n

Al finalizar, comprender√°s c√≥mo convertir un proyecto desde datos sin procesar hasta un modelo de aprendizaje autom√°tico completamente entrenado y probado.

## 2. Objetivos de aprendizaje

- Comprender las categor√≠as b√°sicas de los modelos de aprendizaje autom√°tico
- Distinguir entre regresi√≥n y clasificaci√≥n
- Reconocer problemas de aprendizaje no supervisado
- Entrenar y evaluar un modelo simple
- Entender qu√© es la validaci√≥n cruzada y por qu√© es importante


## 3. Descripci√≥n general del aprendizaje autom√°tico cl√°sico

El aprendizaje autom√°tico cl√°sico se refiere a un grupo de algoritmos y t√©cnicas fundamentales que se desarrollaron antes del r√°pido crecimiento del aprendizaje profundo y las redes neuronales. Estos m√©todos se siguen utilizando ampliamente hoy en d√≠a gracias a su rapidez, f√°cil interpretaci√≥n y eficacia para resolver numerosos problemas del mundo real.

<kbd><img src="images/SupervisedvsUnsupervised.webp" style="border:1px solid grey; border-radius:10px;"></kbd>

**Tipos de aprendizaje en el aprendizaje autom√°tico cl√°sico:**

En el aprendizaje autom√°tico cl√°sico, existen varios tipos de m√©todos de aprendizaje. Los dos m√°s comunes son el **Supervised Learning** y el **Unsupervised Learning**, pero tambi√©n existen otros, como el **Semi-Supervised** y el **Reinforcement Learning**, que desempe√±an un papel importante en situaciones espec√≠ficas.

---

### Aprendizaje supervisado 

El aprendizaje supervisado utiliza **datos etiquetados**, lo que significa que cada ejemplo de entrenamiento incluye tanto caracter√≠sticas de entrada como una salida correcta (etiqueta).

üìå **Objetivo:** Aprender una funci√≥n que asigne entradas a salidas.

üìå **Ejemplo:** Predecir el precio de las viviendas bas√°ndose en caracter√≠sticas como el tama√±o, la ubicaci√≥n y el n√∫mero de habitaciones.

Los algoritmos de aprendizaje supervisado se dividen en dos categor√≠as seg√∫n el tipo de salida:

**1) Classification Algorithms (Predecir categor√≠as discretas)**
- Logistic Regression  
- Support Vector Machines (SVM)  
- k-Nearest Neighbors (k-NN)  
- Decision Trees  
- Random Forest  
- Naive Bayes  
- Gradient Boosting (XGBoost, AdaBoost, etc..)

**2) Regression Algorithms (Predecir valores continuos)**
- Linear Regression  
- Ridge/Lasso Regression  
- Support Vector Regression (SVR)  
- Decision Tree Regressor  
- Random Forest Regressor  
- k-Nearest Neighbors (k-NN) Regression

### Aprendizaje no supervisado

El aprendizaje no supervisado funciona con "datos no etiquetados". El algoritmo intenta encontrar patrones, agrupaciones o estructuras en los datos sin conocer de antemano el resultado correcto.

<kbd><img src="images/Supervised-and-unsupervised.png" style="border:1px solid grey; border-radius:10px;"></kbd>

üìå **Objetivo:** Descubrir estructuras o relaciones ocultas en los datos

üìå **Ejemplo:** Segmentar a los clientes en diferentes grupos seg√∫n su comportamiento de compra

üìå **¬øC√≥mo reconocerlo?** No hay una columna de "objetivo" o el objetivo es agrupar, comprimir o resumir los datos

El aprendizaje no supervisado incluye las siguientes categor√≠as:

#### 1) Clustering Algorithms 

Los algoritmos de agrupamiento se utilizan para agrupar autom√°ticamente puntos de datos en grupos seg√∫n su similitud, sin necesidad de datos etiquetados.

- K-Means  
- Hierarchical Clustering  
- DBSCAN  
- Mean Shift

#### 2) Dimensionality Reduction Algorithms 

Las t√©cnicas de reducci√≥n de dimensionalidad simplifican los conjuntos de datos al reducir la cantidad de caracter√≠sticas de entrada y, al mismo tiempo, preservar informaci√≥n y patrones importantes.

- Principal Component Analysis (PCA)  
- t-SNE  
- Autoencoders *(transitions into deep learning)*  
- Factor Analysis

<kbd><img src="images/dimensionalityReduction.png" style="border:1px solid grey; border-radius:10px;"></kbd>

#### 3) Association Rule Learning 

El aprendizaje de reglas de asociaci√≥n encuentra relaciones y patrones entre variables en grandes conjuntos de datos.

- Apriori  
- Eclat

---

Todos estos algoritmos implican mucha matem√°tica y razonamiento. Esta es una de las partes m√°s f√°ciles de **implementar**, pero una de las m√°s dif√≠ciles de **comprender a fondo**. Para aprender m√°s, puedes explorar explicaciones visuales, tutoriales en l√≠nea o profundizar en la teor√≠a para comprender c√≥mo y por qu√© funcionan en la pr√°ctica.

[Explicaci√≥n matem√°tica y visual de algunos algoritmos](https://mlu-explain.github.io/)


### Otros tipos de aprendizaje

**Aprendizaje semisupervisado:** combina una peque√±a cantidad de datos etiquetados con una gran cantidad de datos sin etiquetar. Esto es √∫til cuando el etiquetado es costoso o requiere mucho tiempo, y aun as√≠ queremos aprovechar las ventajas del aprendizaje supervisado.

**Aprendizaje por refuerzo:** implica que un modelo aprende interactuando con un entorno y recibiendo recompensas o penalizaciones. Aunque es menos com√∫n en el aprendizaje autom√°tico cl√°sico, se utiliza ampliamente en √°reas como la rob√≥tica, los agentes de videojuegos y los sistemas de recomendaci√≥n.

## 4. Entrenamiento de un modelo simple de aprendizaje autom√°tico

Ahora viene la parte divertida: ¬°entrenar un modelo de aprendizaje autom√°tico!

Una vez que los datos est√©n limpios, transformados y listos, el proceso de codificaci√≥n es sorprendentemente sencillo. En muchos casos, solo se necesita una sola importaci√≥n y unas pocas l√≠neas de c√≥digo para comenzar.

### Pasos t√≠picos para entrenar un modelo:

1. **Dividir los datos**: Divide tu conjunto de datos en conjuntos de entrenamiento y de prueba.
2. **Define el objetivo**: Determina si tu problema es *supervisado* o *no supervisado*.
3. **Elige un algoritmo**: Seg√∫n tu objetivo, selecciona algunos modelos aplicables para probar.
4. **Entrenamiento y prueba**: Entrena el modelo con tus datos de entrenamiento y luego pru√©balo con los datos de prueba no vistos.
5. **Evaluaci√≥n del rendimiento**: Utiliza m√©tricas como **exactitud**, **precisi√≥n** o **error cuadr√°tico medio** para decidir qu√© modelo funciona mejor.

Es com√∫n probar varios modelos y comparar su rendimiento antes de elegir el mejor.

---

### Ejemplo: K-Nearest Neighbors Classifier

```python
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)

# Crear y entrenar al modelo.
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)

# Hacer predicciones y evaluar
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
```
## 5. M√©tricas de Rendimiento

Tras entrenar un modelo, necesitamos una forma de medir su rendimiento. Aqu√≠ es donde entran en juego las **m√©tricas de rendimiento**. La m√©trica adecuada depende del tipo de problema y de lo que m√°s importa en tu caso de uso espec√≠fico.

No todos los "buenos" resultados significan lo mismo. Un modelo puede parecer excelente a primera vista, pero fallar en las √°reas m√°s importantes para tu objetivo.


**Ejemplo 1: Filtro de spam (Clasificaci√≥n):**

Supongamos que est√°s creando un modelo para detectar correos spam.

- **Precisi√≥n** = Cu√°ntos correos acert√≥ el modelo en total.
  Si tu modelo tiene una precisi√≥n del 95%, ¬°genial!

Pero ¬øqu√© pasa si el modelo omite mucho spam o, peor a√∫n, marca correos reales como spam?

Aqu√≠ entran en juego otras dos m√©tricas:

- **Precisi√≥n** = De los correos marcados como spam, ¬øcu√°ntos eran realmente spam?
  Una alta precisi√≥n significa menos **falsas alarmas**.

- **Recordatorio** = De todos los correos spam reales, ¬øcu√°ntos detect√≥ el modelo?
  Un alto recordatorio significa menos **spam omitido**.

üìå **Si no hay problema con no detectar el spam, pero marcar correos electr√≥nicos reales como spam es un problema, opta por una alta precisi√≥n.**

üìå **Si detectar todo el spam es fundamental (incluso si algunos correos electr√≥nicos reales est√°n marcados incorrectamente), opta por una alta capacidad de recuperaci√≥n.**



**Ejemplo 2: Predicci√≥n del precio de la vivienda (Regresi√≥n):**

Ahora imagina que est√°s prediciendo el precio de la vivienda. El modelo indica que una casa vale **$300,000**, pero el valor real es **$310,000**. Eso supone un **error de $10,000**.

Utilizamos estas m√©tricas para medir la desviaci√≥n de las predicciones:

- **MAE (Error Absoluto Medio)** = En promedio, ¬øcu√°ntos d√≥lares nos desviamos? 
- **MSE (Error Cuadr√°tico Medio)** = La misma idea, pero **los errores m√°s grandes se penalizan m√°s** porque se elevan al cuadrado.
- **RMSE (Error Cuadr√°tico Medio)** = Similar al MSE, pero restablece el resultado en las unidades originales (como d√≥lares).
- **Puntuaci√≥n R¬≤** = Cuantifica qu√© tan bien se alinean las predicciones de un modelo de regresi√≥n con los datos reales (cuanto m√°s cerca de 1, mejor).

üìå **Si los errores peque√±os son aceptables**, use MAE.

üìå **Si los errores grandes son realmente graves**, use MSE o RMSE para penalizarlos m√°s.

üìå **Si desea saber cu√°nta varianza explica su modelo**, use R¬≤.

El objetivo es elegir siempre la m√©trica que coincida con el **impacto real** de sus predicciones. Un buen modelo en un caso puede no ser adecuado para otro, dependiendo de qu√© errores sean m√°s importantes.

## 6. Validaci√≥n cruzada

En nuestro ejemplo anterior, utilizamos un enfoque com√∫n: dividir el conjunto de datos en dos partes: una para entrenamiento y otra para pruebas. Si bien esto es simple y ampliamente utilizado, presenta un problema. Una sola divisi√≥n entre entrenamiento y prueba puede ser **poco fiable**, especialmente con conjuntos de datos peque√±os. El rendimiento del modelo puede variar significativamente seg√∫n c√≥mo se dividan los datos.

Aqu√≠ es donde entra en juego la **Validaci√≥n cruzada**.

<kbd><img src="images/cross_validation.png" style="border:1px solid grey; border-radius:10px;"></kbd>

La validaci√≥n cruzada es un m√©todo m√°s **robusto y fiable** para evaluar un modelo de aprendizaje autom√°tico. En lugar de entrenar y probar el modelo una sola vez, la validaci√≥n cruzada divide los datos en varias partes (denominadas **folds**). El modelo se entrena y prueba varias veces, cada vez utilizando un fold diferente para las pruebas y el resto para el entrenamiento.

Al final, se promedian los resultados de cada ejecuci√≥n para obtener una estimaci√≥n m√°s estable y precisa del rendimiento del modelo.

- Proporciona una **mejor estimaci√≥n** del rendimiento del modelo
- Ayuda a **prevenir el sobreajuste**
- **Reduce la varianza** causada por divisiones aleatorias entre entrenamiento y prueba

La validaci√≥n cruzada es especialmente importante al ajustar hiperpar√°metros o comparar diferentes modelos. Garantiza que el rendimiento observado no sea solo el resultado de una divisi√≥n fortuita de datos.

## 7. Evaluaci√≥n del Modelo y Ajuste de Hiperpar√°metros

Entrenar un modelo es solo el comienzo. Despu√©s, los siguientes pasos son:

- **Evaluar su rendimiento**
- **Mejorarlo mediante ajustes**

---

### Evaluaci√≥n del Modelo

Una vez elegido un modelo y entrenado, es necesario evaluar su rendimiento. Esto implica analizar las **m√©tricas de rendimiento** (como la exactitud, la precisi√≥n o el MAE) y detectar problemas como:

- **Sobreajuste**: El modelo funciona muy bien con los datos de entrenamiento, pero mal con los datos no analizados.
- **Subajuste**: El modelo funciona mal tanto con los datos de entrenamiento como con los de prueba porque no ha aprendido lo suficiente.  

<kbd><img src="images/OverfitingvsUnderfitting.svg" style="border:1px solid grey; border-radius:10px;"></kbd>

En esta figura, las l√≠neas representan nuestro modelo (o funci√≥n) y los puntos son nuestros datos. Cada escenario muestra la capacidad de generalizaci√≥n del modelo (su capacidad para realizar predicciones precisas con datos nuevos e in√©ditos).

Esto significa que, al introducir un nuevo dato que el modelo no ha visto antes, queremos que realice una predicci√≥n lo m√°s cercana posible al valor real.

- En el caso de sobreajuste, el modelo es demasiado complejo e intenta ajustar cada punto de los datos de entrenamiento, incluso el ruido. Si bien puede funcionar muy bien con el conjunto de entrenamiento, no logra generalizar y su rendimiento es deficiente con datos nuevos.

- En el caso de subajuste, el modelo es demasiado simple y no captura el patr√≥n subyacente en los datos. Su rendimiento es deficiente tanto con los datos de entrenamiento como con los nuevos porque no ha aprendido lo suficiente.

- En el ajuste ideal, el modelo captura el verdadero patr√≥n subyacente sin complicar las cosas. Su rendimiento es bueno tanto con los datos de entrenamiento como con los nuevos, mostrando una buena generalizaci√≥n.

El objetivo es encontrar el equilibrio adecuado, donde el modelo sea lo suficientemente complejo como para aprender los patrones importantes, pero no tan complejo como para memorizar los datos.

**C√≥mo implementar:**
Para detectar estos problemas, utilice gr√°ficos como las curvas de precisi√≥n o error durante el entrenamiento.

<kbd><img src="images/OvsUGraph.jpeg" style="border:1px solid grey; border-radius:10px;"></kbd>

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

# Tenemos nuestras caracter√≠sticas y objetivo
X = df.drop[columns='target']
y = df['target']

# Elige un modelo simple
model = LogisticRegression(max_iter=200)

# Obtener datos de la curva de aprendizaje
train_sizes, train_scores, val_scores = learning_curve(
    model, X, y, cv=5, scoring='accuracy'
)

# Calcular puntuaciones promedio en todos los pliegues
train_scores_mean = np.mean(train_scores, axis=1)
val_scores_mean = np.mean(val_scores, axis=1)

# Trazar los gr√°ficos
plt.plot(train_sizes, train_scores_mean, label='Training Score')
plt.plot(train_sizes, val_scores_mean, label='Validation Score')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve')
plt.legend()
plt.grid(True)
plt.show()
```
---

### Ajuste de hiperpar√°metros

Cada modelo tiene par√°metros ajustables, llamados *hiperpar√°metros*. Estos no se aprenden de los datos, sino que se definen antes de comenzar el entrenamiento.

#### Ejemplo:
Para *K-Nearest Neighbors (KNN)*, un hiperpar√°metro clave es:

- `n_neighbors`: ¬øCu√°ntos puntos cercanos debe considerar el modelo?

Puede probar diferentes valores, como 3, 5 o 7, y comparar su precisi√≥n.

### Hiperpar√°metros comunes por modelo

| Model              | Common Hyperparameters                    |
|-------------------|--------------------------------------------|
| KNN                | `n_neighbors`                              |
| Decision Tree      | `max_depth`, `min_samples_split`           |
| Random Forest      | `n_estimators`, `max_depth`                |
| SVM                | `C`, `kernel`, `gamma`                     |
| Gradient Boosting  | `learning_rate`, `n_estimators`, `max_depth` |

La parte m√°s dif√≠cil del ajuste de hiperpar√°metros es comprender **qu√© hiperpar√°metros ajustar y por qu√©**. Esto requiere una comprensi√≥n m√°s profunda del funcionamiento interno de cada algoritmo de aprendizaje autom√°tico, y profundizar en ello ser√≠a demasiado extenso para esta presentaci√≥n.

En su lugar, recomiendo empezar por algo sencillo:

Elige **un algoritmo** que est√©s usando y b√∫scalo en l√≠nea para ver qu√© es y c√≥mo funciona. Luego, consulta la **documentaci√≥n de Scikit-learn** para ver qu√© hiperpar√°metros est√°n disponibles y qu√© controlan.

C√©ntrate en comprender algunos **hiperpar√°metros clave** que suelen afectar el comportamiento del modelo y experimenta modificando ligeramente sus valores. Esto te ayudar√° a ver c√≥mo peque√±os ajustes pueden afectar la precisi√≥n, el sobreajuste o el subajuste del modelo.

A medida que te sientas m√°s c√≥modo, empezar√°s a reconocer qu√© hiperpar√°metros son m√°s importantes para los diferentes tipos de problemas.

Por ahora, solo recuerda:
- Los **hiperpar√°metros** son ajustes que defines antes de entrenar tu modelo (como `n_neighbors` en KNN). - Son diferentes de los **par√°metros**, que el modelo aprende durante el entrenamiento.

### ¬øC√≥mo ajustar?

Normalmente combinamos el ajuste de hiperpar√°metros con la **Validaci√≥n cruzada**, utilizando herramientas como la **Grid Search**.

La B√∫squeda en cuadr√≠cula es un m√©todo que prueba autom√°ticamente todas las combinaciones posibles de valores de hiperpar√°metros para encontrar la configuraci√≥n del modelo con mejor rendimiento.

#### Ejemplo de Gridsearch:

```python
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier

params = {'n_neighbors': [3, 5, 7, 9]}
grid = GridSearchCV(KNeighborsClassifier(), params, cv=5)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best Score:", grid.best_score_)
```

## 8. Conclusi√≥n y Pr√≥ximos pasos

En este punto, has completado **todo el proceso de aprendizaje autom√°tico** de principio a fin:

- Exploraste y depuraste tus datos
- Los transformaste para que estuvieran listos para el modelo
- Elegiste los algoritmos adecuados
- Entrenaste y evaluaste m√∫ltiples modelos
- Los ajustaste para mejorar el rendimiento

Ahora solo queda **comunicar tus resultados** de forma clara e impactante, ya sea mediante un panel, un informe o una presentaci√≥n. Presentar tus hallazgos eficazmente es el paso final que demuestra el valor de todo lo que has hecho.


#### ¬øQu√© sigue?

Ahora que ha completado el ciclo completo de modelado, desde la preparaci√≥n de datos hasta el entrenamiento, la evaluaci√≥n y el ajuste de los modelos, ha construido una base s√≥lida en el aprendizaje autom√°tico cl√°sico.

En la pr√≥xima presentaci√≥n, profundizaremos en varios temas clave que hemos abordado y exploraremos nuevos conceptos.

Analizaremos **t√©cnicas avanzadas de limpieza de datos** para gestionar conjuntos de datos reales desordenados, incluyendo m√©todos m√°s inteligentes para gestionar valores at√≠picos, valores faltantes y datos con ruido.

Tambi√©n se presentar√°n **t√©cnicas de reducci√≥n de dimensionalidad**, como el **An√°lisis de Componentes Principales (PCA)**, que ayudan a simplificar conjuntos de datos complejos a la vez que preservan la informaci√≥n m√°s importante.

Tambi√©n presentaremos las **neural networks**, explicando c√≥mo imitan el cerebro para resolver problemas m√°s complejos y por qu√© se han convertido en la base de la inteligencia artificial moderna.

Por √∫ltimo, cubriremos los **pipelines**, que ayudan a automatizar y organizar todo el flujo de trabajo de aprendizaje autom√°tico.


